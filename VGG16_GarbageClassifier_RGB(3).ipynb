{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "VGG16_GarbageClassifier_RGB(3).ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bp3aCUPAfjr1",
        "outputId": "ada227a8-e9a4-41e4-a086-1d3fdd548aad"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lvw9fZLXsuO-"
      },
      "source": [
        "!unzip /content/gdrive/MyDrive/dataset_3.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OsiDT9Oenhuq"
      },
      "source": [
        "# Каталог с данными для обучения\n",
        "train_dir = '/content/dataset_3/train'\n",
        "# Каталог с данными для проверки\n",
        "val_dir = '/content/dataset_3/validation'\n",
        "# Каталог с данными для тестирования\n",
        "test_dir = '/content/dataset_3/test'\n",
        "# Размеры изображения\n",
        "img_width, img_height = 50, 50\n",
        "# Размерность тензора на основе изображения для входных данных в нейронную сеть\n",
        "input_shape = (img_width, img_height, 3)\n",
        "# Количество эпох\n",
        "epochs = 80\n",
        "# Размер мини-выборки\n",
        "batch_size = 32\n",
        "#Количество изображений для обучения\n",
        "nb_train_samples = 4761\n",
        "# Количество изображений для проверки\n",
        "nb_validation_samples = 345\n",
        "# Количество изображений для тестирования\n",
        "nb_test_samples = 345"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H59MJzihs4RH"
      },
      "source": [
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D\n",
        "from keras.models import model_from_json\n",
        "from keras.models import load_model\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.optimizers import Nadam\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from keras.models import Model\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "# Загружаем свёрточные слои VGG16 без возможности изменения весов\n",
        "\n",
        "conv = VGG16(include_top=False, input_shape=input_shape)\n",
        "for layer in conv.layers:\n",
        "\tlayer.trainable = False\n",
        "#Добавляем полносвязные слои\n",
        "model = Sequential()\n",
        "\n",
        "model.add(conv)\n",
        "model.add(Flatten())\n",
        "model.add(Dense(1024, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(3, activation='softmax'))\n",
        "\n",
        "#Компилируем модель\n",
        "model.compile(loss=\"categorical_crossentropy\",\n",
        "\t\t\t\toptimizer=Nadam(lr=1e-4),\n",
        "\t\t\t\tmetrics=[\"accuracy\"])\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lRH655ODPL99",
        "outputId": "7b56c2a5-014d-4a85-b62c-c076b129060e"
      },
      "source": [
        "# Инициализируем ImageDataGenerator для аугментации изображений \n",
        "from keras. preprocessing. image import ImageDataGenerator\n",
        "datagen = ImageDataGenerator( featurewise_center=False,samplewise_center=False,featurewise_std_normalization=False,\n",
        "                              samplewise_std_normalization = False,zca_whitening=False,rotation_range=0.5,\n",
        "                              zoom_range=0.5,width_shift_range=0.5,height_shift_range=0.5,horizontal_flip=True,rescale=1. / 255, vertical_flip=True)\n",
        "\n",
        "test_generator = datagen.flow_from_directory(\n",
        "    test_dir,\n",
        "    target_size=(img_width, img_height),\n",
        "    batch_size =batch_size,\n",
        "    class_mode='categorical')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 1035 images belonging to 3 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sInMZmG9lyHo"
      },
      "source": [
        "\n",
        "\n",
        "train_generator = datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(img_width, img_height),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical')\n",
        "\n",
        "\n",
        "val_generator = datagen.flow_from_directory(\n",
        "    val_dir,\n",
        "    target_size=(img_width, img_height),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical')\n",
        "\n",
        "\n",
        "# Запускаем тренировочный процесс\n",
        "history = model.fit_generator(\n",
        "    train_generator,\n",
        "    steps_per_epoch=nb_train_samples // batch_size,\n",
        "    epochs=epochs,\n",
        "    validation_data=val_generator,\n",
        "    validation_steps= (nb_validation_samples // batch_size))\n",
        "\n",
        "# Сохраняем структуру сети и веса нейронов\n",
        "#model_json = model.to_json()\n",
        "with open(\"VGG_GarbageClassifier_RGB.json\", \"w\") as json_file :\n",
        "\tjson_file.write(model_json)\n",
        "\n",
        "model.save_weights(\"VGG16_GarbageClassifier_RGB5.h5\")\n",
        "print(\"Saved model to disk\")\n",
        "\n",
        "model.save('VGG_GarbageClassifier_RGB.model')\n",
        "\n",
        "#Рисуем диаграмму точности по мере обучения\n",
        "print(history.history.keys())\n",
        "plt.figure(1)\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'validation'], loc='upper left')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r30bBNnNmZ0R",
        "outputId": "974552ee-c5d8-4a83-db60-379168b148af"
      },
      "source": [
        "# Оцениваем качество обучения модели на тестовой выборке \n",
        "model.load_weights('VGG16_GarbageClassifier_RGB5.h5')\n",
        "scores = model.evaluate_generator(test_generator, nb_test_samples // batch_size)\n",
        "print(scores[1]*100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1973: UserWarning: `Model.evaluate_generator` is deprecated and will be removed in a future version. Please use `Model.evaluate`, which supports generators.\n",
            "  warnings.warn('`Model.evaluate_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "79.6875\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6oDE_91HdXb9",
        "outputId": "76f167ac-aa42-40e2-97dc-1279c5aa0070"
      },
      "source": [
        "#Проверим работу сети на изображении металической консервной банки, взятой из интеренета    \n",
        "import cv2\n",
        "CATEGORIES = [\"glass\",\"metal\",\"plastic\"]\n",
        "#Функция, подготавливающая изображение к подаче в нейросеть\n",
        "def prepare(file):\n",
        "    IMG_SIZE = 50\n",
        "    img_array = cv2.imread(file)\n",
        "    new_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))\n",
        "    return new_array.reshape(-1, IMG_SIZE, IMG_SIZE, 3)\n",
        "model = tf.keras.models.load_model(\"VGG_GarbageClassifier_RGB.model\")\n",
        "image = \"/content/gdrive/MyDrive/matal1.jpg\" \n",
        "image = prepare(image)\n",
        "prediction = model.predict([image])\n",
        "prediction = list(prediction[0])\n",
        "for i in range(len(CATEGORIES)):\n",
        "  print(CATEGORIES[i],prediction[i]*100)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "glass 0.05012294859625399\n",
            "metal 79.97218370437622\n",
            "plastic 19.977685809135437\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kHwH5NgKT2g-"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}